{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***#들어가기_skicit learn*** (87p ~ 99p)\n",
    "=======\n",
    "### **[목차]**\n",
    "#### 1. 사이킷런 이란?\n",
    "#### 2. 간단하게 붓꽃 품종 예측하기\n",
    "#### 3. 사이킷런 주요 모듈 알아보기\n",
    "#### 4. 사이킷런에 내장된 에제 데이터 세트 알아보기\n",
    "----------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. 사이킷런(scikit learn)이란?**\n",
    ": 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리\n",
    "\n",
    ": 최근에는 텐서플로 , 케라스 등 딥러닝 전문 라이브러리의 강세로 대중적인 관심이 줄어들고 있으나 여전히 대표적인 파이썬 ML라이브러리\n",
    "\n",
    "* sklearn.datasets 내의 모듈은 사이킷런에서 자체적으로 제공하는 데이터세트를 생성하는 모듈의 모임\n",
    "* sklearn.tree : 트리기반 ML알고리즘을 구현한 클래스 모임\n",
    "* sklearn.model_selection : 학습데이터와 검증데이터 , 예측데이터로 분리 / 최적의 하이퍼파라미터*를 평가하기 위한 다양한 모듈의 모임\n",
    "\n",
    "(하이퍼 파라미터 : 머신러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터를 통칭, 하이퍼파라미터를 통해 머신러닝 알고리즘의 성능을 튜닝함 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris                #irisi데이터 부르기 (import sklean.datasets.load_iris)\n",
    "from sklearn.model_selection import train_test_split  #데이터세트를 학습/테스트 로 분리\n",
    "from sklearn.tree import DecisionTreeClassifier       #의사결정트리 알고리즘을 구현\n",
    "from sklearn.metrics import accuracy_score            #정확도 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. 붓꽃 품종 예측하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1) 데이터부르기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris= load_iris() \n",
    "iris ## in a text editor를 통해 보다 자세히 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iris는 피처(feature)만으로 된 데이터 numpy를 가지고 있음\n",
    "iris_data=iris.data\n",
    "\n",
    "#iris는 레이블(결정 값)만으로 된 데이터 numpy를 가지고 있음\n",
    "iris_label = iris.target\n",
    "\n",
    "#피처데이터 프레임으로 만들기\n",
    "iris = pd.DataFrame(iris_data , columns=iris['feature_names'])\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2) 데이터 세트 분리하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### [`sklearn.model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection \"sklearn.model_selection\").train_test_split[](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split \"Permalink to this headline\")\n",
    "\n",
    "sklearn.model_selection.train_test_split(_*arrays_,  _test_size=None_,  _train_size=None_,  _random_state=None_,  _shuffle=True_,  _stratify=None_)\n",
    "\n",
    "\n",
    ">> **parameters**\n",
    "\n",
    "* **arrays** : sequence of indexables with same length / shape[0]\n",
    "\n",
    "Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
    "\n",
    "허용되는 입력은 목록, numpy 배열, scipy-sparse 행렬 또는 팬더 데이터 프레임입니다.\n",
    "\n",
    "\n",
    "* **test_size** : float or int, default=None\n",
    "\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. <br/>\n",
    "If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size.<br/>\n",
    " If  `train_size`  is also None, it will be set to 0.25.\n",
    "\n",
    "부동인 경우 0.0과 1.0 사이여야 하며 시험 분할에 포함할 데이터 집합의 비율을 나타냅니다.<br/>\n",
    "int인 경우 검정 표본의 절대 수를 나타냅니다. 없음인 경우 이 값은 열차 크기의 보수로 설정됩니다. train_size도 None이면 0.25로 설정됩니다.<br/>\n",
    "\n",
    "* **train_size** : float or int, default=None\n",
    "\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.\n",
    "\n",
    "플로트인 경우 0.0과 1.0 사이여야 하며 훈련데이터 분할에 포함할 데이터 세트의 비율을 나타냅니다. int인 경우 훈련데이터 샘플의 절대 수를 나타냅니다. 없음인 경우 값은 테스트 크기의 보수로 자동으로 설정됩니다.\n",
    "\n",
    "* **random_state** : int, RandomState instance or None, default=None\n",
    "\n",
    "Controls the shuffling applied to the data before applying the split. </b>\n",
    "분할을 적용하기 전에 데이터에 적용되는 셔플링을 제어합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>* X_train : 학습용 피처      | X_test : 테스트용 피처\n",
    ">>>* y_train : 학습용 레이블    | y_test : 테스트용 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data , iris_label, test_size = 0.2 , random_state= 11)\n",
    "\n",
    "# 첫번째 파라미터 : 피처데이터세트 \n",
    "# 두번째 파라미터 : 레이블데이터 세트 \n",
    "# 세번째파라미터 : 전체 데이터 세트 중 테스트 데이터 세트의 비율\n",
    "# 네번째 파라미터 : 호출할때 마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3) 의사결정 트리를 통한 학습과 예측 수행**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ### [`sklearn.tree`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree \"sklearn.tree\").DecisionTreeClassifier[](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn-tree-decisiontreeclassifier \"Permalink to this headline\")\n",
    "\n",
    "_class_ sklearn.tree.DecisionTreeClassifier(_*_,  _criterion='gini'_,  _splitter='best'_,  _max_depth=None_,  _min_samples_split=2_,  _min_samples_leaf=1_,  _min_weight_fraction_leaf=0.0_,  _max_features=None_,  _random_state=None_,  _max_leaf_nodes=None_,  _min_impurity_decrease=0.0_,  _class_weight=None_,  _ccp_alpha=0.0_)\n",
    "\n",
    "*자세한 내용은 뒤에서 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> **ML순서**\n",
    "1) 먼저 사이킷런의 의사결정트리클래스인 DecisionTreeClassifier를 객체로 생성\n",
    "2) 생성된 DecisionTreeClassifier객체의 fit()메서드에 학습용 피터데이터 속성과 레이블세트를 입력해 학습을 수행한다.\n",
    "3) DecisonTreeClassifier 객체의 predict()메서드에 테스트용 피터데이터 세트를 입력해 예측값 반환\n",
    "4) 예측 성능 평가로 정확도를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state= 11) #객체생성\n",
    "dt_clf.fit(X_train, y_train) #학습수행\n",
    "pred = dt_clf.predict(X_test) #학습이 완료된 dt_clf에 테스트데이터로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정화도 : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f'예측 정확도 : {accuracy_score(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. 사이킷런 주요 모듈 알아보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> + **피처 처리** <br/>\n",
    ">      - sklearn.preoprocessing     : 데이터 전처리에 필요한 다양한 가공 기능 제공 (문자열을 숫자형 코드값으로 인코딩 , 정규화, 스케일 등)<br/>\n",
    ">      - sklearn.feature_selection  : 알고리즘에 큰 영향을 피치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공  <br/>\n",
    ">      - sklearn.feature_extraction : 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용  <br>\n",
    "\n",
    ">>               <예>\n",
    ">>               텍스트 데이터에서 count vectiorizer나 Tf-Idf vectorizer등을 생성하는 기능제공\n",
    ">>               텍스트 데이터의 피처 추출은 sklearn.feature_extraction , text모듈에\n",
    ">>               이미지 데이터의 피처 추출은 sklearn.feature_extraction.image모듈에 지원 API가 있음\n",
    "\n",
    "> + **피처처리 & 차원 축소** <br/>\n",
    ">      - sklearn.decomposition : 차원축소와 관련한 알고리즘을 지언하는 모듈로, PCA, NMF, Truncated SVD등을 통해 차원 축소 기능 수행 <br>\n",
    "> + **데이터분리,검증 & 파라미터 튜닝**<br>\n",
    ">      - sklearn.model_selection : 교차검증을 위한 학습용/테스트용 분리, 그리드 서치로 최적 파라미터 추출 등의 API제공<br>\n",
    "> + **평가** <br>\n",
    ">      - sklearn.metrics : 분류, 회귀, 클러스터링, 페어와이즈에 대한 다양한 성능 측정 방법 제공 Accuracy, Precision, Recalll, ROC-AUC, RMSE제공<br>\n",
    "> + **ML알고리즘**<br>\n",
    ">      - sklearn.ensemble     : 앙상블 알고리즘 , 랜덤포레스트, 에이다 부스트, 그래디언트 부스팅 제공\n",
    ">      - sklearn.linear_model : 주로 선형회귀 , 릿지, 라쏘, 및 로지스틱 회귀 같은 회귀알고리즘 지원, SGD(Stochastic Gradient Descent)관련 알고리즘도 제공\n",
    ">      - sklearn.naives_bayes : 나이브 베이즈 알고리즘 제공, 가우시안NB, 다항분포 NB등\n",
    ">      - sklearn.neighbors    : 최근접 이웃 알고리즘 제공, KNN 등\n",
    ">      - sklearn.svm          : 서포트 벡터 머신 알고리즘 제공\n",
    ">      - sklearn.tree         : 의사결정 트리 알고리즘 제공\n",
    ">      - sklearn.cluster      : 비지도 클러스터링 알고리증 제공(K-평균, 계층형, DBSCAN제공) <br>\n",
    "> + **유틸리티**<br>\n",
    ">      - sklearn.pipeline : 피처 처리 등의 변환과 ML알고리즘 학습, 예측 등을 함께 묶어서 실행 할 수 있는 유틸리티 제공 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. 내장된 예제 데이터 세트**\n",
    "사이킷런에는 별도의 외부 웹사이트에서 데이터 세트를 내려받을 필요 없이 예제로 활용할 수 있는 간단하면서 좋은 데이터 세트가 내장 되어있음.<br>\n",
    "앞으로 내장 되어 있는 데이터 세트로 분류나 회귀를 연습할 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "    <th>API명 </th>\n",
    "    <th> 설명 </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>datasets.load_boston()</td>\n",
    "    <td>회귀용도/ 미국 보스턴 집 피터들과 가격에 대한 데이터 세트</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>datasets.load_breast_cancer()</td>\n",
    "    <td>분류용도/위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>datasets.load_diabetes</td>\n",
    "    <td>회귀용도/당뇨데이터세트</td>  \n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>datasets.load_digits()</td>\n",
    "    <td>분류용도/0에서 9까지 숫자의 이미지 픽셀 데이터 세트</td>\n",
    "  </tr>\n",
    "\n",
    "   <tr>\n",
    "    <td>datasets.load_iris()</td>\n",
    "    <td>분류용도/붓꽃에 대한 피처를 가진 데이터 세트</td>\n",
    "  </tr>\n",
    "\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### 내장된 데이터 세트 자세히 살펴보기\n",
    "    1. 딕셔너리 형태로 되어 있음.\n",
    "    2. 키는 보통 data, target_name , feature_names, DESCR로 구성\n",
    "        + data : 피처의 데이터 세트\n",
    "        - target : 분류 시 레이블 값, 회귀일 때는 숫자 결괏값의 데이터 세트\n",
    "        - target_naems : 개별 레이블 이름\n",
    "        - feature_names : 피처의 이름\n",
    "        - DESCR : 데이터 세트에 대한 설명 + 각 피처의 설명\n",
    "    3. data, target :  넘파이 배열 <br>\n",
    "       target_namse, featrue_names : 넘파이 배열 or 파이썬 리스트<br>\n",
    "       DESCR : 스트링 \n",
    "\n",
    "**-> 따라서 데이터 값을 반환 받기 위해서는 내장 데이터 세트 API를 호출 한 뒤 , 그 key값을 지정**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d240ba0dc525c389faa33f5dcce5b4f32b6d6aa6d70d6d2dd929bd2b09ab69f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
